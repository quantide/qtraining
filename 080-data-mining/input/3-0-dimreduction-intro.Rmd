---
title: "Statistical Methods for Data Dimensionality Reduction"
---

```{r options, include=FALSE, purl=FALSE}
source("options.R")
```

```{r first, include=FALSE, purl=TRUE, message=FALSE}
# This code chunk contains R code already described in the previous chapters
# that is required by following examples

## Datasets from packages
# none

## Other datasets used
# none

###########################
## packages needed: none ##
###########################
```


# Introduction

Dealing with high-dimensional data, in particular nowadays in the big data era, you may be confused on how to analyse and exploit the huge quantity of information provided by hundreds of variables. It would be great to use only few new variables which provide almost the same information of the original ones.

In this part we will present three (groups of) statistical methods for reducing the number of variables contained in the data by keeping almost the same information, in particular:

1. **Multidimensional Scaling (MDS)**: ii is useful to create maps of the observations on few dimensions (two or three, generally) starting from a lot of variables;
2. **Principal Component Analysis (PCA)** and **Explorative Factor Analysis (EFA)**: they are useful to reduce a set of numerical variables;
3. brief outlines on **Correspondence Analysis (CA)**: it is useful to reduce a set of categorical variables.

