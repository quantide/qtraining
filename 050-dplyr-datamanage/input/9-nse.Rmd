---
title: "Non-Standard Evaluation"
---

```{r options, include=FALSE, purl=FALSE}
options(width = 108)
```

```{r first, include=TRUE, purl=TRUE, message=FALSE}
require(dplyr)
require(qdata)
require(lazyeval)
data(bank)
```


# Programming with `dplyr`

Package `dplyr` has been developed to provide end users with a tool for effective yet easy data manipulation tool. Nevertheless, when developing R code with `dplyr`, you may notice some apparently strange behavior. Suppose you to create a simple function that, for any `tbl` object filters for all value of a variable above a given threshold. The `dplyr` interactive code for achieving this, applied as an example to data frame `mtcars`, can be:

```{r}
filter(mtcars, disp > 450) 
```

In case you want to generalize this task you may decide to write a simple function:

```{r}
fun1 <- function(data, x, threshold) {
  filter(data, x > threshold)
}  
```

Unfortunately, this function is not going to work:

```{r, error = TRUE}
fun1(mtcars, x = disp, threshold = 450)
```

All of this happens as function `fun1()` looks for an object named `disp` within its environment rather that within data frame `mtcars`.

while a slightly more complicated version of the same function would work perfectly:

```{r}
fun2 <- function(data, x, threshold) {
  quoted <- paste(substitute(x), threshold, sep = '>')
  filter_(data, quoted)
}  
fun2(tbl_df(mtcars), x = disp, threshold = 450)
```


You may decide to use the capabilities offered by package `lazyeval`

```{r message=FALSE}
require(lazyeval)
```

```{r}
fun3 <- function(data, x, threshold) {
  lazy_x <- lazy(x)
  x <- lazy_eval(lazy_x, data)
  data[x > threshold, ]
}  

fun3(mtcars, x = disp, threshold = 450)
```

and possibly use an escape hatch mechanism as provided by package `dplyr`  

```{r}
fun4_ <- function(data, x, threshold) {
  x <- lazy_eval(x, data)
  data[x > threshold, ]
}  

fun4_(mtcars, x = 'disp', threshold = 450)

fun4 <- function(data, x, threshold) {
  x <- lazy(x)
  fun4_(data = data, x = x, threshold = threshold) 
}

fun4(mtcars, x = disp, threshold = 450)
```

A main advantage of functions `fun4()` and `fun4_()` consists in the decoupling of the programming into two layers: 

* a layer, made of function `fun4_()`, suitable for programming  
* a layer, made of function `fun4()`, suitable for interactive use


# NSE vs SE in `dplyr`

`dplyr` uses non-standard evaluation (NSE) in all of the most important single table verbs: `filter()`, `mutate()`, `summarise()`, `arrange()`, `select()` and `group_by()`. 

NSE is great as for interactive use as:

* allows writing `R` instruction without quoting variables
* saves time when coding
* keeps yout code simpler

On the other hand, NSE is hard to program with.

Fortunatelly, every function in `dplyr` that uses NSE also has a version that uses SE. There’s a consistent naming scheme: the SE is the NSE name with `_` on the end. For example, the SE version of `summarise()` is `summarise_()`, the SE version of `arrange()` is `arrange_()`.

These functions work very similarly to their NSE counterparts, but the inputs must be “quoted”.

That is, the NSE version of `summarise()`:

```{r}
summarise(bank, mean_balance = mean(balance, na.rm = TRUE))
```

corrensponds to three possible SE versions:

* with a formula:

```{r}
summarise_(bank, mean_balance = ~mean(balance, na.rm = TRUE))
```

* with `quote()`:

```{r}
summarise_(bank, mean_balance = quote(mean(balance, na.rm = TRUE))) 
```

* as a string:

```{r}
summarise_(bank, mean_balance = "mean(balance, na.rm = TRUE)")
```


<!--- da capire

It’s better to use a formula, because a formula captures both the expression to evaluate, and the environment in which it should be a evaluated. This is important if the expression is a mixture of variables in the data frame and objects in the local environment:

```{r}
constant1 <- function(n) ~n
summarise_(bank, constant1(4))
```

Using anything other than a formula will fail because it doesn't know which environment to look in:

```{r error=TRUE}
constant2 <- function(n) quote(n)
summarise_(bank, constant2(4))
``` 
---> 




If you also want to output variables to vary, you need to pass a list of quoted objects to the `.dots` argument:

```{r}
n <- 10
dots <- list(~mean(balance, na.rm = TRUE), ~n)
summarise_(bank, .dots = dots)
```

Better results can be gained using function `setNames()`: a convenience function that sets the names on an object and returns the object. 

```{r}
summarise_(bank, .dots = setNames(dots, c("mean", "count"))) 
```


# Mixing Constants and Variables

You may want to mix constants and variables in the same call: that is the variable and the function are passed as arguments.

Suppose you want to write a function `summarise_by(data, g , x , fun)` that summarise `data` by `g` by computing `fun(x)`.

In this case you may want to write first prepare the SE version: `summarise_by_()`:


```{r}
summarise_by_ <- function(data, g , x , fun){
  
  # prepare input
  dots <- setNames(
    list(
      interp(~n()),
      interp( ~fun(x), x = as.name(x))),
    c("n", "fun"))
  
  # compute  
  data <- data %>% 
    group_by_(g) %>%
    summarise_(.dots = dots)
  
  # return
  return(data)      
}

summarise_by_(mtcars, g = "cyl", x = "disp", fun = mean)
```

Function `summarise_()` taks as input an agument `.dots` a list of quoted objects: `dots`.

List `dots` is made of two elements named: `n` and `fun` resulting from two calls to function `interp()` from package `lazyeval`. 

Function `interp()` interpolates values into an expression (call):

```{r}
x <- 1:10
interp(~mean(x), as.name(x))
```

So that `dots` results in a list of two calls to be latter evaluated by function `summarise_()`

After the SE version `summarise_by_()` you can easily build up NSE version: `summarise_by()`:

```{r}
summarise_by <- function(data, g, x, fun){
  g <- substitute(g)
  x <- substitute(x)
  summarise_by_ (data, g , x , fun)
}  

summarise_by (mtcars, g = cyl , x = disp , fun = mean)
```

