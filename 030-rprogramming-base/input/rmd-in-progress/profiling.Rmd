---
title: "Profiling in R and RStudio"
---


```{r options, include=FALSE, purl=FALSE}
options(width = 108)
```


## Introduction


## Measuring code performance

One way to check how long your function is taking to run, is to use the `microbenchmark` package. If you want to compare how long you are gaining, by, for example, switching from a `for` cycle to a functional, the `microbenchmark` function may come in handy. 

Suppose you want a function that:

1. deletes one row
2. estimate a model on the remaining observations
3. makes a prediction on that one observation
4. finds the residual 
5. saves it

This must be applied on all rows, meaning that each row at the time must be taken out of the dataframe.

First you build a function that does actions 1-5:

```{r}
# funzione che fa tutta la parte sopra
require(microbenchmark)
.cross_validation <- function(data, i, formula) {
  training <- data[-i,]
  test <- data[i,]
  fm <- lm(formula, data = training)
  out <- predict(fm, newdata = test)
  return(out)
}

```

and then a function that does a cycle over the above function:

```{r}
# funzione che fa il ciclo per applicare a tutte le righe
cross_validation1 <- function(data, formula) {
  n <- nrow(data)
  cv <- numeric(n)
  for (i in 1:n) {
    cv_i <- .cross_validation(data, i, formula)
    cv[i] <- cv_i
  }
  return(cv)
}
```

Now, we know that `for` cycles are not as fast as functionals. So let us see if we can recode it by using a functional:

```{r}
cross_validation2 <- function(data, formula) {
  n <- nrow(data)
  cv <- lapply(1:n, .cross_validation, data = data, formula)
  return(cv)
}

```

and finally, you may want to compare the two functions:

```{r}

data(mtcars)

microbenchmark(
  cross_validation1(data = mtcars, formula = mtcars$mpg ~ mtcars$hp),
  cross_validation2(data = mtcars, formula = mtcars$mpg ~ mtcars$hp), 1
)
```


Focus on the median time, and use the upper and lower quartiles to gauge the variability of the measurement.


## Profiling tools in R and RStudio

